{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from docx import Document\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])  # Extract all paragraphs\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "best_practices_file_path = \"./data/The CyberGov™ Framework – Optimizing Your Cybersecurity Posture v. 8.0 14 Dec 2023.docx\"\n",
    "board_report_file_path = \"./data/Sample board of directors meeting.docx\"\n",
    "board_memo_file_path = \"./data/Board Memo 1 March 14.docx\"\n",
    "\n",
    "best_practices_text = read_docx(best_practices_file_path)\n",
    "board_report_text = read_docx(board_report_file_path)\n",
    "board_memo_text = read_docx(board_memo_file_path)\n",
    "\n",
    "best_practices_doc = Document(best_practices_text, metadata={\"source\":best_practices_file_path})\n",
    "board_report_doc = Document(board_report_text, metadata={\"source\":board_report_file_path})\n",
    "board_memo_doc = Document(board_memo_text, metadata={\"source\":board_memo_file_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "best_practices_doc = Document(best_practices_text, metadata={\"source\":best_practices_file_path})\n",
    "board_report_doc = Document(board_report_text, metadata={\"source\":board_report_file_path})\n",
    "board_memo_doc = Document(board_memo_text, metadata={\"source\":board_memo_file_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt at the Baseline LLM Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document as LCDocument\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Split document into smaller chunks for embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_text(board_report_text)\n",
    "\n",
    "# Convert chunks into LangChain Document objects\n",
    "docs = [LCDocument(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Store embeddings in FAISS vector database\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save FAISS index for later use\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# Load FAISS index (optional, for retrieval)\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\"status\":\"Fail\",\"explanation\":\"While the board confirmed that the policies, '\n",
      " 'processes, and procedures for managing cyber breaches are well-established, '\n",
      " 'they have not been updated since the last meeting, which violates the annual '\n",
      " 'review requirement for compliance with Practice '\n",
      " '4.1.\",\"corrective_measures\":\"Schedule an immediate review and update of the '\n",
      " 'cyber breach management documents to meet the annual requirement, and ensure '\n",
      " 'that a maintenance schedule is established to avoid future lapses in '\n",
      " 'compliance.\"}')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ComplianceReport(BaseModel):\n",
    "    status: str\n",
    "    explanation: str\n",
    "    corrective_measures: str\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define best practice statement\n",
    "practice = \"Practice 4.1: Policies, processes, and procedures for managing cyber breaches internally are established and reviewed at least annually.\"\n",
    "\n",
    "# Retrieve top 5 most relevant documents with similarity scores\n",
    "retrieved_docs = vector_store.similarity_search_with_score(practice, k=5)\n",
    "\n",
    "# Format retrieved documents into a structured prompt\n",
    "context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\" for i, (doc, score) in enumerate(retrieved_docs)])\n",
    "\n",
    "# Construct the final prompt\n",
    "final_prompt = f\"\"\"\n",
    "You are an expert compliance analyst tasked with evaluating the compliance status of the best practice based on the provided context. \n",
    "The context consists of relevant remarks from board members. Clearly state the status in your response as \"Pass\" or \"Fail\" at the top.\n",
    "\n",
    "### Best Practice:\n",
    "{practice}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Based on the context, does the organization comply with this best practice? Provide reasoning if it doesn't and corrective measures. Your description should be easy to comprehend. If you don't find any relevant information, you can state that as well.\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert compliance analyst.\"},\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ],\n",
    "    response_format=ComplianceReport\n",
    ")\n",
    "\n",
    "pprint(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j Graph Over Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(url=\"bolt://localhost:7687\", username=\"neo4j\", password=\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_best_practices(text):\n",
    "    principles = []\n",
    "    current_principle = None\n",
    "    \n",
    "    lines = text.strip().split(\"\\n\")  # Split by lines\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        principle_match = re.match(r\"^Principle (\\d+\\.\\d+): (.+)\", line)\n",
    "        practice_match = re.match(r\"^Practice (\\d+\\.\\d+): (.+)\", line)\n",
    "        \n",
    "        if principle_match:\n",
    "            if current_principle:\n",
    "                principles.append(current_principle)\n",
    "            current_principle = {\n",
    "                \"id\": principle_match.group(1),\n",
    "                \"name\": principle_match.group(2),\n",
    "                \"practices\": []\n",
    "            }\n",
    "        elif practice_match and current_principle:\n",
    "            current_principle[\"practices\"].append({\n",
    "                \"id\": practice_match.group(1),\n",
    "                \"description\": practice_match.group(2)\n",
    "            })\n",
    "    \n",
    "    if current_principle:\n",
    "        principles.append(current_principle)\n",
    "    \n",
    "    return principles\n",
    "\n",
    "principles=parse_best_practices(best_practices_text)\n",
    "\n",
    "# workaround for an anomaly in the data\n",
    "# principles[2]['practices'][1]['id'] = '3.1.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of schema queries\n",
    "queries = [\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT unique_principle_id IF NOT EXISTS \n",
    "    FOR (p:Principle) REQUIRE p.id IS UNIQUE\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT unique_practice_id IF NOT EXISTS \n",
    "    FOR (pr:Practice) REQUIRE pr.id IS UNIQUE\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT unique_keyindicator_details IF NOT EXISTS \n",
    "    FOR (ki:KeyIndicator) REQUIRE ki.details IS UNIQUE\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting data into Neo4j\n",
    "for principle in principles:\n",
    "    # Ensure Principle node is created or matched\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "        MERGE (p:Principle {id: $principle_id})\n",
    "        ON CREATE SET p.name = $principle_name\n",
    "        \"\"\",\n",
    "        params={\"principle_id\": principle[\"id\"], \"principle_name\": principle[\"name\"]},\n",
    "    )\n",
    "\n",
    "    for practice in principle[\"practices\"]:\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "            MATCH (p:Principle {id: $principle_id})  // Ensure Principle exists\n",
    "            MERGE (pr:Practice {id: $practice_id})  // Ensure unique Practice by ID\n",
    "            ON CREATE SET pr.description = $practice_desc  // Set description only on creation\n",
    "            MERGE (p)-[:HAS_PRACTICE]->(pr)  // Create relationship\n",
    "            \"\"\",\n",
    "            params={\n",
    "                \"principle_id\": principle[\"id\"],\n",
    "                \"practice_id\": practice[\"id\"],\n",
    "                \"practice_desc\": practice[\"description\"],\n",
    "            },\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'node_count': 42}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (n) RETURN count(n) AS node_count;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (n) DETACH DELETE n;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key indicators mapped to their corresponding practice IDs (provided by Bob)\n",
    "key_indicators = {\n",
    "    \"2.6\": [\n",
    "        \"How can we guarantee that all subsidiaries fully implement cybersecurity communication channels?\",\n",
    "        \"What barriers might delay the complete deployment of these communication frameworks, and how can they be mitigated?\",\n",
    "        \"How do we foster greater trust among suppliers and third parties to encourage transparency in cybersecurity risk sharing?\",\n",
    "        \"Could leveraging contractual obligations improve data-sharing practices with external partners?\",\n",
    "    ],\n",
    "    \"3.4\": [\n",
    "        \"What mechanisms can be implemented to extend supply chain cybersecurity risk management to international vendors?\",\n",
    "        \"What challenges might arise from merging cybersecurity risk with enterprise risk management, and how can they be resolved?\",\n",
    "        \"How can board members be encouraged to perceive cybersecurity as a key component of corporate governance rather than a standalone function?\",\n",
    "    ],\n",
    "    \"4.5\": [\n",
    "        \"How can we better model cyber risks to enhance response planning in unpredictable scenarios?\",\n",
    "        \"What initiatives can be introduced to align staff and board perspectives on a unified incident response strategy?\",\n",
    "        \"How can we ensure that real-world data collection is comprehensive and accessible across all business units?\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Insert key indicators and establish relationships\n",
    "for practice_id, questions in key_indicators.items():\n",
    "    for question in questions:\n",
    "        graph.query(\n",
    "            \"\"\"\n",
    "            MATCH (pr:Practice {id: $practice_id})\n",
    "            MERGE (ki:KeyIndicator {question: $question})\n",
    "            MERGE (pr)-[:HAS_KEY_INDICATOR]->(ki)\n",
    "            \"\"\",\n",
    "            params={\"practice_id\": practice_id, \"question\": question},\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'p': {'name': 'Plan', 'id': '2.0'}, 'pr': {'description': ' Lines of communication across the organization are established for cybersecurity risks, including risks from suppliers and other third parties. GV.RM-05', 'id': '2.6'}, 'ki': {'question': 'Does leveraging contractual obligations improve data-sharing practices with external partners?'}}, {'p': {'name': 'Plan', 'id': '2.0'}, 'pr': {'description': ' Lines of communication across the organization are established for cybersecurity risks, including risks from suppliers and other third parties. GV.RM-05', 'id': '2.6'}, 'ki': {'question': 'Could leveraging contractual obligations improve data-sharing practices with external partners?'}}, {'p': {'name': 'Plan', 'id': '2.0'}, 'pr': {'description': ' Lines of communication across the organization are established for cybersecurity risks, including risks from suppliers and other third parties. GV.RM-05', 'id': '2.6'}, 'ki': {'question': 'How do we foster greater trust among suppliers and third parties to encourage transparency in cybersecurity risk sharing?'}}, {'p': {'name': 'Plan', 'id': '2.0'}, 'pr': {'description': ' Lines of communication across the organization are established for cybersecurity risks, including risks from suppliers and other third parties. GV.RM-05', 'id': '2.6'}, 'ki': {'question': 'What barriers might delay the complete deployment of these communication frameworks, and how can they be mitigated?'}}, {'p': {'name': 'Plan', 'id': '2.0'}, 'pr': {'description': ' Lines of communication across the organization are established for cybersecurity risks, including risks from suppliers and other third parties. GV.RM-05', 'id': '2.6'}, 'ki': {'question': 'How can we guarantee that all subsidiaries fully implement cybersecurity communication channels?'}}]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve principle and related practices along with key indicators (if any)\n",
    "principle_id = \"2.0\"\n",
    "\n",
    "result = graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (p:Principle)-[:HAS_PRACTICE]->(pr:Practice)-[:HAS_KEY_INDICATOR]->(ki:KeyIndicator)\n",
    "    WHERE p.id = $principle_id\n",
    "    RETURN p, pr, ki;\n",
    "    \"\"\",\n",
    "    params={\"principle_id\": principle_id}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Practice: 2.6\n",
      "    Key Indicator: Could leveraging contractual obligations improve data-sharing practices with external partners?\n",
      "  Practice: 2.6\n",
      "    Key Indicator: How do we foster greater trust among suppliers and third parties to encourage transparency in cybersecurity risk sharing?\n",
      "  Practice: 2.6\n",
      "    Key Indicator: What barriers might delay the complete deployment of these communication frameworks, and how can they be mitigated?\n",
      "  Practice: 2.6\n",
      "    Key Indicator: How can we guarantee that all subsidiaries fully implement cybersecurity communication channels?\n",
      "  Practice: 3.4\n",
      "    Key Indicator: How can board members be encouraged to perceive cybersecurity as a key component of corporate governance rather than a standalone function?\n",
      "  Practice: 3.4\n",
      "    Key Indicator: What challenges might arise from merging cybersecurity risk with enterprise risk management, and how can they be resolved?\n",
      "  Practice: 3.4\n",
      "    Key Indicator: What mechanisms can be implemented to extend supply chain cybersecurity risk management to international vendors?\n",
      "  Practice: 4.5\n",
      "    Key Indicator: How can we ensure that real-world data collection is comprehensive and accessible across all business units?\n",
      "  Practice: 4.5\n",
      "    Key Indicator: What initiatives can be introduced to align staff and board perspectives on a unified incident response strategy?\n",
      "  Practice: 4.5\n",
      "    Key Indicator: How can we better model cyber risks to enhance response planning in unpredictable scenarios?\n"
     ]
    }
   ],
   "source": [
    "def traverse_and_print_key_indicators(graph, principle_id):\n",
    "    result = graph.query(\n",
    "        \"\"\"\n",
    "        MATCH (p:Principle)-[:HAS_PRACTICE]->(pr:Practice)-[:HAS_KEY_INDICATOR]->(ki:KeyIndicator)\n",
    "        WHERE p.id = $principle_id\n",
    "        RETURN p, pr, ki;\n",
    "        \"\"\",\n",
    "        params={\"principle_id\": principle_id}\n",
    "    )\n",
    "\n",
    "    for record in result:\n",
    "        # principle = record[\"p\"]\n",
    "        practice = record[\"pr\"]\n",
    "        key_indicator = record[\"ki\"]\n",
    "\n",
    "        if key_indicator:\n",
    "            # print(f\"Principle: {principle['name']}\")\n",
    "            print(f\"  Practice: {practice['id']}\")\n",
    "            print(f\"    Key Indicator: {key_indicator['question']}\")\n",
    "\n",
    "for principle in principles:\n",
    "    traverse_and_print_key_indicators(graph, principle[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document as LCDocument\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Split document into smaller chunks for embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_text(board_memo_text)\n",
    "\n",
    "# Convert chunks into LangChain Document objects\n",
    "docs = [LCDocument(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Store embeddings in FAISS vector database\n",
    "vector_store_memo = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# # Save FAISS index for later use\n",
    "# vector_store_memo.save_local(\"faiss_index_memo\")\n",
    "\n",
    "# # Load FAISS index (optional, for retrieval)\n",
    "# vector_store_memo = FAISS.load_local(\"faiss_index_memo\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Fail\n",
      "Cause: The organization has not established or reviewed internal policies for managing cyber breaches annually.\n",
      "Explanation: While the board acknowledges the importance of preparing for potential cyber incidents and has discussions around incident response, there is no clear indication that formal policies, processes, and procedures for managing internal cyber breaches are in place or that these have been reviewed at least annually. The focus appears to be on communication, collaboration, and planning rather than the establishment and regular review of formalized policies.\n",
      "Corrective measures: Develop and implement written policies, processes, and procedures specifically for managing cyber breaches. Ensure these documents are reviewed at least annually and incorporate lessons learned from previous incidents to enhance their effectiveness.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "\n",
    "\n",
    "class ComplianceReport(BaseModel):\n",
    "    status: str = Field(description=\"The compliance status: 'Pass' or 'Fail'\")\n",
    "    causality: str = Field(description=\"A to-the-point concise reason (Cause) for the compliance status (Effect)\")\n",
    "    explanation: str = Field(description=\"Explanation of the compliance status finding\")\n",
    "    corrective_measures: str = Field(\n",
    "        description=\"Suggested corrective measures if status is 'Fail', or empty if 'Pass'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a parser for the ComplianceReport model\n",
    "parser = PydanticOutputParser(pydantic_object=ComplianceReport)\n",
    "\n",
    "# Define the prompt template with instructions for JSON formatting\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an expert compliance analyst tasked with evaluating the compliance status of the best practice based on the provided context. \n",
    "The context consists of relevant remarks from board members. Clearly state the status in your response as \"Pass\" or \"Fail\" at the top.\n",
    "You will be provided with a key indicator and a practice statement. You need to evaluate the compliance status of the practice based on the key indicator.\n",
    "\n",
    "### Best Practice:\n",
    "{practice}\n",
    "\n",
    "### Key Indicator:\n",
    "{key_indicator}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Based on the context, does the organization comply with this best practice? Provide reasoning if it doesn't and corrective measures. Your description should be easy to comprehend. If you don't find any relevant information, you can state that as well.\n",
    "\n",
    "Format your response as a JSON object with the following fields:\n",
    "- status: \"Pass\" or \"Fail\"\n",
    "- causality: A to-the-point concise reason (Cause) for the compliance status (Effect)\n",
    "- explanation: A detailed explanation of why the organization passes or fails\n",
    "- corrective_measures: Suggested actions if failing, or empty string if passing\n",
    "\n",
    "### Answer:\n",
    "\"\"\",\n",
    "    input_variables=[\"practice\", \"key_indicator\", \"context\"],\n",
    ")\n",
    "\n",
    "# Initialize the LLM with JSON output format\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\", model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    ")\n",
    "\n",
    "# Create the compliance chain\n",
    "compliance_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt_template, output_key=\"compliance_report\"\n",
    ")\n",
    "\n",
    "\n",
    "# Function to run the compliance check with vector retrieval\n",
    "def check_compliance(practice_statement, key_indicator, vector_store, k=5):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vector_store.similarity_search_with_score(practice_statement, k=k)\n",
    "\n",
    "    # Format retrieved documents into a structured context\n",
    "    context = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"Document {i+1} (score: {score}):\\n{doc.page_content}\"\n",
    "            for i, (doc, score) in enumerate(retrieved_docs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run the compliance chain\n",
    "    result = compliance_chain.invoke(\n",
    "        {\"practice\": practice_statement, \"key_indicator\": key_indicator, \"context\": context}\n",
    "    )\n",
    "\n",
    "    # Parse the JSON string into a ComplianceReport object\n",
    "    try:\n",
    "        json_str = result[\"compliance_report\"]\n",
    "        parsed_json = json.loads(json_str)\n",
    "        return ComplianceReport(**parsed_json)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse result into ComplianceReport model. Error: {e}\")\n",
    "        print(\"Raw result:\")\n",
    "        pprint(result[\"compliance_report\"])\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "practice = \"Practice 4.1: Policies, processes, and procedures for managing cyber breaches internally are established and reviewed at least annually.\"\n",
    "key_indicator = \"Not Provided\"\n",
    "report = check_compliance(practice, key_indicator, vector_store_memo, k=5)\n",
    "if report:\n",
    "    print(f\"Status: {report.status}\")\n",
    "    print(f\"Cause: {report.causality}\")\n",
    "    print(f\"Explanation: {report.explanation}\")\n",
    "    print(f\"Corrective measures: {report.corrective_measures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Practice:** 2.6\n",
      "**Key Indicator:** Could leveraging contractual obligations improve data-sharing practices with external partners?\n",
      "**Status:** Pass\n",
      "**Cause:** The board is establishing communication channels to address cybersecurity risk sharing.\n",
      "**Explanation:** The board has recognized the importance of establishing uniform cybersecurity communication channels across all subsidiaries, which includes addressing concerns about supplier and third-party transparency regarding cybersecurity risks. The discussion around secure, automated reporting mechanisms demonstrates a proactive approach to improving data-sharing practices with external partners, thus aligning with the best practice of establishing lines of communication for cybersecurity risks.\n",
      "**Corrective measures:** \n",
      "\n",
      "**Practice:** 2.6\n",
      "**Key Indicator:** How do we foster greater trust among suppliers and third parties to encourage transparency in cybersecurity risk sharing?\n",
      "**Status:** Fail\n",
      "**Cause:** Lack of established and effective communication channels for cybersecurity risk sharing with suppliers and third parties.\n",
      "**Explanation:** The context suggests that while the board recognizes the need for uniform cybersecurity communication channels and the importance of addressing suppliers' reluctance to share risk information, specific mechanisms to promote transparency amongst suppliers and third parties have not been fully implemented. Although there are discussions on secure, automated reporting mechanisms, there is still a gap in fostering trust and open communication, as these practices are not yet operational or effectively utilized.\n",
      "**Corrective measures:** Implement secure, automated reporting mechanisms to facilitate transparency and trust in sharing cybersecurity risks. Additionally, develop training sessions or workshops for suppliers and third parties focused on the importance of cybersecurity risk sharing, thereby encouraging an open and collaborative communication environment.\n",
      "\n",
      "**Practice:** 2.6\n",
      "**Key Indicator:** What barriers might delay the complete deployment of these communication frameworks, and how can they be mitigated?\n",
      "**Status:** Fail\n",
      "**Cause:** Reluctance from suppliers and third parties to share risk information hinders full deployment of communication frameworks.\n",
      "**Explanation:** The context highlights a significant barrier to the establishment of effective communication channels regarding cybersecurity risks. The board has expressed awareness of the reluctance of suppliers and third parties to share critical cybersecurity information, which is essential for mitigating risks. Although discussions on secure and automated reporting mechanisms have been initiated, the specific implementation of the communication framework is still pending and not fully realized. This indicates that while there is recognition of the need for such communication, the actual deployment is delayed due to external factors, particularly with third-party collaborations.\n",
      "**Corrective measures:** The organization should focus on strategies to build trust with suppliers and third parties, ensuring that they feel secure in sharing cybersecurity data. This could include developing comprehensive guidelines on data protection, conducting workshops to educate counterparts on the importance of open communication, or leveraging technology to facilitate secure information sharing.\n",
      "\n",
      "**Practice:** 2.6\n",
      "**Key Indicator:** How can we guarantee that all subsidiaries fully implement cybersecurity communication channels?\n",
      "**Status:** Fail\n",
      "**Cause:** Uniform cybersecurity communication channels are not fully established across all subsidiaries.\n",
      "**Explanation:** The board recognizes the need to establish uniform cybersecurity communication channels across all subsidiaries but has yet to implement these effectively. There is a discussion about reluctance from suppliers and third parties to share necessary information, indicating gaps in communication. Furthermore, although there are strategies being explored to expedite the rollout, there is no indication that these have been fully put into action or that all subsidiaries are adhering to these practices.\n",
      "**Corrective measures:** Implement and enforce standardized procedures for cybersecurity communication across all subsidiaries, and ensure that all key stakeholders, including suppliers and third parties, are educated on the importance of sharing cybersecurity risk information. Establish a timeline for the rollout of secure communication mechanisms and monitor compliance regularly.\n",
      "\n",
      "**Practice:** 3.4\n",
      "**Key Indicator:** How can board members be encouraged to perceive cybersecurity as a key component of corporate governance rather than a standalone function?\n",
      "**Status:** Pass\n",
      "**Cause:** The board's discussions indicate a recognition of cybersecurity as integral to enterprise risk management.\n",
      "**Explanation:** The context shows that board members are actively engaging in discussions about integrating cybersecurity supply chain risk management into the broader enterprise risk management framework. They are also recognizing cybersecurity as a critical element of enterprise-wide risk, not just a technical issue. This reflects an understanding that cybersecurity is not a standalone function but rather intertwined with overall corporate governance, aligning with the best practice of integration into risk management processes.\n",
      "**Corrective measures:** \n",
      "\n",
      "**Practice:** 3.4\n",
      "**Key Indicator:** What challenges might arise from merging cybersecurity risk with enterprise risk management, and how can they be resolved?\n",
      "**Status:** Pass\n",
      "**Cause:** The board recognizes the importance of integrating cybersecurity risk into enterprise risk management.\n",
      "**Explanation:** The context provided indicates that the board is actively discussing the integration of cybersecurity supply chain risk management within the broader enterprise risk management framework. They acknowledge the necessity for a global approach and stress that cybersecurity should be included as a fundamental component of enterprise risk. The discussions held suggest a proactive stance in merging these risk management areas, pointing towards a good understanding of the critical nature of cybersecurity in enterprise risk management.\n",
      "**Corrective measures:** \n",
      "\n",
      "**Practice:** 3.4\n",
      "**Key Indicator:** What mechanisms can be implemented to extend supply chain cybersecurity risk management to international vendors?\n",
      "**Status:** Fail\n",
      "**Cause:** The organization has acknowledged the need to extend its strategy to include international vendors but lacks concrete mechanisms to do so.\n",
      "**Explanation:** While the board recognizes the importance of integrating cybersecurity supply chain risk management into their enterprise risk management framework, and has acknowledged the need to expand their strategy to include global suppliers, there is no mention of specific mechanisms or practices implemented to effectively manage cybersecurity risks from international vendors. The discussions indicate an awareness of the issue but lack actionable steps or a framework for execution.\n",
      "**Corrective measures:** Develop and implement specific mechanisms for assessing and managing the cybersecurity risks associated with international vendors. This could include creating guidelines for vendor risk assessments, establishing communication channels with international suppliers, and regular training for board members on global cybersecurity considerations.\n",
      "\n",
      "**Practice:** 4.5\n",
      "**Key Indicator:** How can we ensure that real-world data collection is comprehensive and accessible across all business units?\n",
      "**Status:** Fail\n",
      "**Cause:** Insufficient detail on real-world data collection across all business units.\n",
      "**Explanation:** The board members recognize the importance of regular practice sessions and the need for real-time data accessibility; however, the documents lack comprehensive strategies or methodologies for ensuring that real-world data collection is thorough and accessible across various business units. While there are discussions around collaboration and enhancing enterprise-wide preparedness, specific measures for data collection, management, and accessibility across the organization remain unclear.\n",
      "**Corrective measures:** Develop a structured framework for data collection that includes input from all business units, create centralized data repositories for real-world data, and establish protocols for ensuring data accessibility to all relevant stakeholders involved in incident response.\n",
      "\n",
      "**Practice:** 4.5\n",
      "**Key Indicator:** What initiatives can be introduced to align staff and board perspectives on a unified incident response strategy?\n",
      "**Status:** Pass\n",
      "**Cause:** The board recognizes the importance of practice sessions and collaboration on incident response strategy.\n",
      "**Explanation:** The context indicates that the board values regular practice sessions to prepare for cyber events and is actively discussing methods to align staff and board perspectives on an incident response framework. Their focus on planning, communication, and implementation signifies a structured approach to incident response preparedness, which aligns with the best practice of conducting regular practice sessions utilizing real data in planning.\n",
      "**Corrective measures:** \n",
      "\n",
      "**Practice:** 4.5\n",
      "**Key Indicator:** How can we better model cyber risks to enhance response planning in unpredictable scenarios?\n",
      "**Status:** Fail\n",
      "**Cause:** The board's discussions lack concrete plans for conducting regular practice sessions using real data.\n",
      "**Explanation:** While the board acknowledged the importance of regular practice sessions and discussed methodologies to anticipate cyber incidents, there is no evidence in the documents that these practices are being regularly conducted. Moreover, the focus on enhancing response planning in unpredictable scenarios suggests that they recognize the need for better modeling of cyber risks, but they have not outlined any specific actions or frameworks for these practice sessions. Therefore, the organization does not meet the compliance requirements stipulated by the best practice.\n",
      "**Corrective measures:** Develop and implement a structured schedule for regular practice sessions that utilize real data. Establish clear methodologies for modeling cyber risks and improve collaboration between staff and board members to ensure a cohesive approach to incident response planning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for principle in principles:\n",
    "    result = graph.query(\n",
    "        \"\"\"\n",
    "        MATCH (p:Principle)-[:HAS_PRACTICE]->(pr:Practice)-[:HAS_KEY_INDICATOR]->(ki:KeyIndicator)\n",
    "        WHERE p.id = $principle_id\n",
    "        RETURN p, pr, ki;\n",
    "        \"\"\",\n",
    "        params={\"principle_id\": principle[\"id\"]},\n",
    "    )\n",
    "\n",
    "    for record in result:\n",
    "        # principle = record[\"p\"]\n",
    "        practice = record[\"pr\"]\n",
    "        key_indicator = record[\"ki\"]\n",
    "\n",
    "        if key_indicator:\n",
    "            # print(f\"Principle: {principle['name']}\")\n",
    "            print(f\"**Practice:** {practice['id']}\")\n",
    "            print(f\"**Key Indicator:** {key_indicator['question']}\")\n",
    "\n",
    "            report = check_compliance(practice[\"description\"], key_indicator[\"question\"], vector_store_memo)\n",
    "            if report:\n",
    "                print(f\"**Status:** {report.status}\")\n",
    "                print(f\"**Cause:** {report.causality}\")\n",
    "                print(f\"**Explanation:** {report.explanation}\")\n",
    "                print(f\"**Corrective measures:** {report.corrective_measures}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation with confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "\n",
    "\n",
    "class ComplianceReport(BaseModel):\n",
    "    status: str = Field(description=\"The compliance status: 'Pass' or 'Fail'\")\n",
    "\n",
    "# Create a parser for the ComplianceReport model\n",
    "parser = PydanticOutputParser(pydantic_object=ComplianceReport)\n",
    "\n",
    "# Define the prompt template with instructions for JSON formatting\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an expert compliance analyst tasked with evaluating the compliance status of the best practice based on the provided context. \n",
    "The context consists of relevant remarks from board members. Clearly state the status in your response as \"Pass\" or \"Fail\" at the top.\n",
    "You will be provided with a key indicator and a practice statement. You need to evaluate the compliance status of the practice based on the key indicator.\n",
    "\n",
    "### Best Practice:\n",
    "{practice}\n",
    "\n",
    "### Key Indicator:\n",
    "{key_indicator}\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "Based on the context, does the organization comply with this best practice? If you don't find any relevant information, you can state that as \"Fail\".\n",
    "\n",
    "Format your response as a JSON object with the following fields:\n",
    "- status: \"Pass\" or \"Fail\"\n",
    "\n",
    "### Answer:\n",
    "\"\"\",\n",
    "    input_variables=[\"practice\", \"key_indicator\", \"context\"],\n",
    ")\n",
    "\n",
    "# Initialize the LLM with JSON output format\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\", model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    ")\n",
    "\n",
    "# Create the compliance chain\n",
    "# compliance_chain = LLMChain(\n",
    "#     llm=llm, prompt=prompt_template, output_key=\"compliance_report\"\n",
    "# )\n",
    "compliance_chain = prompt_template | llm\n",
    "\n",
    "\n",
    "# Function to run the compliance check with vector retrieval\n",
    "def check_compliance(practice_statement, key_indicator, vector_store, k=5):\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vector_store.similarity_search_with_score(practice_statement, k=k)\n",
    "\n",
    "    # Format retrieved documents into a structured context\n",
    "    context = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"Document {i+1} (score: {score}):\\n{doc.page_content}\"\n",
    "            for i, (doc, score) in enumerate(retrieved_docs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run the compliance chain\n",
    "    result = compliance_chain.invoke(\n",
    "        {\"practice\": practice_statement, \"key_indicator\": key_indicator, \"context\": context}\n",
    "    )\n",
    "\n",
    "    return result\n",
    "    # # Parse the JSON string into a ComplianceReport object\n",
    "    # try:\n",
    "    #     json_str = result[\"compliance_report\"]\n",
    "    #     parsed_json = json.loads(json_str)\n",
    "    #     return ComplianceReport(**parsed_json)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Failed to parse result into ComplianceReport model. Error: {e}\")\n",
    "    #     print(\"Raw result:\")\n",
    "    #     pprint(result[\"compliance_report\"])\n",
    "    #     return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "practice = \"Practice 4.1: Policies, processes, and procedures for managing cyber breaches internally are established and reviewed at least annually.\"\n",
    "key_indicator = \"Not Provided\"\n",
    "report = check_compliance(practice, key_indicator, vector_store_memo, k=5)\n",
    "# if report:\n",
    "#     print(f\"Status: {report.status}\")\n",
    "#     print(f\"Explanation: {report.explanation}\")\n",
    "#     print(f\"Corrective measures: {report.corrective_measures}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status='Fail'\n"
     ]
    }
   ],
   "source": [
    "# report\n",
    "parser.parse(report.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France is Paris.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_7c63087da1', 'finish_reason': 'stop', 'logprobs': {'content': [{'token': 'The', 'bytes': [84, 104, 101], 'logprob': -3.7697225e-06, 'top_logprobs': []}, {'token': ' capital', 'bytes': [32, 99, 97, 112, 105, 116, 97, 108], 'logprob': -3.1281633e-07, 'top_logprobs': []}, {'token': ' of', 'bytes': [32, 111, 102], 'logprob': -2.8160932e-06, 'top_logprobs': []}, {'token': ' France', 'bytes': [32, 70, 114, 97, 110, 99, 101], 'logprob': -1.9361265e-07, 'top_logprobs': []}, {'token': ' is', 'bytes': [32, 105, 115], 'logprob': 0.0, 'top_logprobs': []}, {'token': ' Paris', 'bytes': [32, 80, 97, 114, 105, 115], 'logprob': -1.7432603e-06, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -2.4391957e-05, 'top_logprobs': []}], 'refusal': None}} id='run-d482e897-ef3d-4325-9e1c-bc95e5566e65-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Initialize OpenAI model with logprobs enabled\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\",\n",
    "                 temperature=0,\n",
    "                 openai_api_key=openai_api_key,\n",
    "                 model_kwargs={\"logprobs\": True})  # Request log probabilities\n",
    "\n",
    "# Define a prompt\n",
    "message = HumanMessage(content=\"What is the capital of France?\")\n",
    "\n",
    "# Get response with log probabilities\n",
    "response = llm([message])\n",
    "\n",
    "# Print full response including log probabilities\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"country\": \"Pakistan\",\n",
      "  \"capital\": \"Islamabad\"\n",
      "}\n",
      "{'country': 0.0, 'capital': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from llm_confidence.logprobs_handler import LogprobsHandler\n",
    "\n",
    "# Initialize the LogprobsHandler\n",
    "logprobs_handler = LogprobsHandler()\n",
    "\n",
    "def get_completion(\n",
    "        messages: list[dict[str, str]],\n",
    "        model: str = \"gpt-4o\",\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        stop=None,\n",
    "        seed=42,\n",
    "        response_format=None,\n",
    "        logprobs=None,\n",
    "        top_logprobs=None,\n",
    "):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop\": stop,\n",
    "        \"seed\": seed,\n",
    "        \"logprobs\": logprobs,\n",
    "        \"top_logprobs\": top_logprobs,\n",
    "    }\n",
    "    if response_format:\n",
    "        params[\"response_format\"] = response_format\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "    return completion\n",
    "\n",
    "# Set up your OpenAI client with your API key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define a prompt for completion\n",
    "response_raw = get_completion(\n",
    "    [{'role': 'user', 'content': 'Tell me the name of capital of Pakistan, and return the response in JSON format.'}],\n",
    "    logprobs=True,\n",
    "    response_format={'type': 'json_object'}\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "print(response_raw.choices[0].message.content)\n",
    "\n",
    "# Extract the log probabilities from the response\n",
    "response_logprobs = response_raw.choices[0].logprobs.content if hasattr(response_raw.choices[0], 'logprobs') else []\n",
    "\n",
    "# Format the logprobs\n",
    "logprobs_formatted = logprobs_handler.format_logprobs(response_logprobs)\n",
    "\n",
    "# Process the log probabilities to get confidence scores\n",
    "confidence = logprobs_handler.process_logprobs(\n",
    "    logprobs_formatted, \n",
    "    nested_keys_dct={'vat': ['vat_data', 'percent', 'vat_amount', 'exclude_vat_amount']}\n",
    ")\n",
    "\n",
    "# Print the confidence scores\n",
    "print(confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
